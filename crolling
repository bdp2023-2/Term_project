import nest_asyncio
import aiohttp
import asyncio
from bs4 import BeautifulSoup
import csv

nest_asyncio.apply()

# 논문 정보를 저장할 리스트
all_papers = []

async def fetch_page(session, url):
    async with session.get(url) as response:
        return await response.text()

async def scrape_arxiv(page):
    url = f"https://arxiv.org/search/?query=AI&searchtype=all&abstracts=show&order=-announced_date_first&size=50&start={50 * (page - 1)}"
    
    async with aiohttp.ClientSession() as session:
        response = await fetch_page(session, url)
        
        soup = BeautifulSoup(response, 'html.parser')
        paper_links = soup.find_all('li', class_='arxiv-result')
        
        for link in paper_links:
            # 제목
            title_tag = link.find('p', class_='title is-5 mathjax')
            title = title_tag.get_text(separator=' ', strip=True) if title_tag else "Title not found"
            
            # 저자
            authors_tag = link.find('p', class_='authors')
            authors = authors_tag.get_text(separator=' ', strip=True) if authors_tag else "Authors not found"
            
            # 초록
            abstract_tag = link.find('p', class_='abstract mathjax')
            abstract = abstract_tag.get_text(separator=' ', strip=True) if abstract_tag else "Abstract not found"
            
            # 날짜
            date_tag = link.find('p', class_='is-size-7')
            date = date_tag.get_text(separator=' ', strip=True) if date_tag else "Date not found"
            
            # 각 논문 정보를 리스트에 저장
            paper_info = [title, authors, abstract, date]
            all_papers.append(paper_info)

async def main():
    page = 1
    
    while True:
        await scrape_arxiv(page)
        page += 1

        # 전체 페이지 크롤링
        if page > 100:  # 예시로 100페이지까지 크롤링
            break

# 비동기 코드 실행
await main()

# 결과를 CSV 파일로 저장
with open('arxiv_papers3.csv', 'w', newline='', encoding='utf-8') as csvfile:
    csv_writer = csv.writer(csvfile)
    
    # 헤더 추가
    csv_writer.writerow(["Title", "Authors", "Abstract", "Date"])
    
    # 논문 정보 쓰기
    csv_writer.writerows(all_papers)
